---Build systems and their buildfiles
Build systems allow developers to define the command DAG in one or more buildfiles. 
Two types of buildfile syntaxes can be distinguished:
    - declarative Domain Specific Language (DSL)
      Examples: make's makefiles, tup's tupfile, mrmakes rules, tools and dep files.
    - imperative General Purpose Language (GPL)
      The buildsystem provides a library to facilitate command node creation.
      Examples: Bazel's Skylark, tup's Lua

---Yam buildfile
No consensus seems to exist on what approach is best nor on what GPL or DSL is best.
Yam therefore choses, at least for now, to support a hybrid approach inspired by 
tup's rule syntax and by tup's 'run script' feature. In this approach a yam 
buildfile is an executable program with a well-known name, e.g. buildfile.yam.
When executing a buildfile it outputs rules to stdout. Rule syntax is derived from
tup, see section Rule syntax.
Yam interprets the rule output to create command nodes in its DAG.
Note: buildfiles will typically be written in script languages like python
or ruby, e.g. buildfile_yam.py, buildfile_yam.rb. Such files must be passed
to their interpreter, e.g. python buildfile_yam.py. Yam must therefore be
told how to execute the buildfile. E.g. by config file like
    *.rb => ruby %f
    *.py => python %f

Yam makes no assumptions about the language used by the buildfile program.
This implies that yam does not provide a GPL support library to facilitate
generating rules. E.g. a function to generate a compile rule, a link rule, etc.
These functions simplify buildfiles to a series of calls to functions that output
the appropriate rules.

Note: Yam has/had the ambition to support a buildfile language that strictly
seperates rule definitions from dependency declarations. This is hard to
implement without a DSL. Yam drops this ambition, at least for now.

---Buildfile processing
Buidfile processing is the process of executing the buildfile, interpreting
the buildfile output rules and creating command nodes and generated file
nodes.

A file is represented in the graph by a FileNode instance.
A file is a source file or a generated file. It is not possible to distinguish
a source from a generated file by its name because yam does not enforce file 
naming conventions.

When interpreting the buildfile output for each rule one ore more (in case of
a foreach rule) CommandNodes will be constructed and added to the graph. When 
creating a CommandNode it must be passed FileNodes for its cmdInputs, 
order-only-inputs and outputs. Order-only-input and output nodes are FileNodes
for generated files, cmdInputs can be FileNodes for source and/or generated
files. The command node will ensure that the commands that generate the 
order-only-inputs and generated cmdInputs are executed before the command 
script is executed. This requires that:
    - The command node can distinguish a source from a generated input file.
    - It is possible to find the command node that produces the generated file.
    - The command node knows its generated input files before it is executed.
    
Note: file repositories are mirrored in the build graph.
When executing the very first build the mirrored directory tree will only
contain source file nodes. All these nodes can either be looked-up in the 
mirrored tree or directly (and faster) from the graph. After buildfile 
processing the graph, not the mirrored tree, will also contain generated
file nodes. 
When executing the next build the mirror will pickup the files generated by
the first build. The mirroring logic finds associated generated file nodes in 
the graph. So there is no need for the mirroring logic to be able to
distinguish source from generated files because generated file nodes are
created before the generate files are produced.
Exception: user deletes buildstate but not the generated files. In this
case the stale generated files are mirrored as source files. When creating
the generated file nodes yam will detect this conflict and prompt the
user to delete all stale generated files.

Design aspects:
    1) Class design
       a) FileNode has a reference to the CommandNode that produced it.
          If this reference is null than the FileNode is a source file.
          The producer field will be set once the rule is processed that
          defines the command that produces the generated file. 
       b) FileNode has subclasses SourceFileNode and GeneratedFileNode
          The latter has a reference to the CommandNode that produced it
          and that can only be set at construction time.
    2) Number of processing phases
       a) 1-phase (only in combination with 1a)
          The inputs of a command node are all FileNodes. Only after 
          processing of all buildfiles the commands are ready for execution
          because only then one can be sure that the producer fields of all
          generated file nodes are properly initialized. 
       b) 1.5-phase
          If a generated file GF is defined as the output of a rule in
          buildfile Y and GF is referenced as input of a rule in buildfile X
          then Y is processed before X. This ensures that the generated file
          node for GF exists when X is processed. After processing of X the
          commands produced by X are ready for execution.
          Buildfile X is said to depend on buildfile Y.
       c) 2-phase
          First phase creates all command nodes and generated file nodes for 
          their output files.
          Second phase initializes the inputs of the command nodes created in
          first phase.
          Only after processing of the second phase are the commands produced
          in the first phase ready for execution.

2a and 2c (1-phase and 2-phase) require all buildfiles to be processed before
command execution can begin. This limits scalability.

2b (1.1-phase) only requires a subset of all buildfiles to be processed before 
the commands defined in a buildfile can be executed. This enables parallel 
processing of buildfiles and execution of command nodes. The amount of parallel
processing depends on the buildfile dependency graph. E.g. if 1 buildfile
depends on all the others then there will be no parallel execution.

Given these design aspects there are 5 possible design scenarios:

1a+2* (FileNode with optional producer, any nr of processing phases)
Assume the user mis-spelled the name of a generated input file. The buildstate
will not contain this name because no source file of that name exist. 
Hence a FileNode is created (with its producer being null) under the assumption
that it is a generated file and that the node's producer will be initialized 
once the build file is processed that defines the rule that produces that 
generated file. But this will not happen because of the mis-spelled name. As a
consequence the command script will fail because it references a non-existing 
input file. This violates the fail-early principle.

1b+2a (SourceFileNode/GeneratedFileNode and 1-phase)
This combination is not possible because a rule with a generated input file
for which no GeneratedFileNode was yet created can not construct the 
GeneratedFileNode itself because it does not know its producer.

1b+2b (SourceFileNode/GeneratedFileNode and 1.5-phase)
When the proper buildfile dependencies of buildfile X have been processed then
during processing of X the graph will contain all generated input nodes
referenced by X.
In case of missing buildfile dependencies or mis-spelling of a source or
generated input file the graph will not contain a matching SourceFileNode/
/GeneratedFileNode. In this case buildfile processing fails and the user must
correct his error (i.e. fix buildfile dependencies declaration or fix spelling
of input file name).

1b+2c
Similar to previous scenario: when in second phase no matching input node is
found then buildfile processing fails.

The design 1b+2b (SourceFileNode/GeneratedFileNode and 1.5-phase) is the most
attractive because:
    - it enables parallel processing of buildfiles and commands
    - it fails early and is able to produce an error message that explains the 
      two possible causes of the error (incomplete buildfile dependencies or
      mis-spelled input file.)

Decision: implement 1b+2b

---Buildfile dependencies

A buildfile is an executable program that outputs rules that are interpreted by
yam to produce a set of command and generated file nodes. The process of 
executing the buildfile and subsequent interpretation is called buildfile 
processing.

Yam will re-process the buildfile when the buildfile program text and/or one or
more of the buildfile's input dependencies change. Yam supports three types of 
buildfile input dependencies:
    - buildfile
      Buildfile X depends on buildfile Y when X uses definitions made in Y.
      For now only generated files defined by Y. Later perhaps also variables.
      Yam will process Y before X.
      Given design choice 1b+2b it is up to the user to declare the buildfile
      dependencies. Options:
          - declare the buildfile dependency graph in a special file
          - each buildfile outputs the names of it buildfile dependencies
      Decision: each buildfile outputs its buildfile dependencies
    - source file
      Buildfile X depends on src file F when F is read during execution of X.
      Yam will detect such dependencies by monitoring file access of X.
    - directory
      Buildfile X depends on directory D when the set of command nodes defined
      by X depends on the content of D or when a directory is specified as
      rule input. E.g. a buildfile that produces a rule that has an input glob
      on directory D depends on D. E.g. a buildfile that outputs a rule for 
      each .cpp file in directory D depends on D.
      Note: in the first example the yam interpreter evaluates the glob on D 
      and yam will add D to the input dependencies of X. In the second example 
      the buildfile program evaluates the glob on D. Yam however cannot detect 
      directory iteration. The buildfile must therefore output its directory
      dependencies. This is error-prone. In case of mistakes the user will
      quickly notice this (e.g. a new source file will not be compiled).


Perhaps yam could detect directory dependencies like it does detect file 
dependencies. In mrmake directory dependencies and dependencies on non-existing
files were ignored because they often cause unnecessary re-execution. E.g.
a compilation command node searches an include file F by iterating directories
P, Q and R respectively. Assume F is found in R. Now all changes in P, Q and R
cause re-execution of the buildfile/command while only modifying F or moving F
to P or Q or adding a P\F or Q\F justifies such re-executions.
On the other hand: if such a change takes place then the compilation must be
re-executed. How to solve this? 
An easier case is when F is searched by using file_exists calls for P\F, Q\F 
and R\F (assuming file_exists calls can be monitored). In this case one would
register input file dependencies on P\F, Q\F and R\F. Moving F or adding P\F 
or Q\F then correctly results in re-executing the compilation command.

---Rule syntax
Yam rule syntax is simplified tup rule syntax. See file rule_syntax.txt.
Simplifications: no variables, subset of flags. 
Things could be be further simplified by removing foreach support. The foreach is
then implemented in the GPL in the buildfile program. This eliminates substitution 
of %f and other flags. The cmd script can be passed literally to a shell or directly
to the OS. Without foreach a rule defines one command.
For the time being yam will support foreach rules. Rationale: Yam caches directories
and glob results. Such caches cannot be implemented in the buildfile logic. Hence
yam foreach support will result in faster processing of buildfiles.

---BuildFileNode
Processing of buildfile X is performed by a BuildFileNode associated with a
SourceFileNode associated with X. BuildFileNodes are stored in the graph.
BuildFileNode keeps track of the command and generated file nodes created by
that BuildFileNode and added to the graph. It owns these nodes, i.e. it is 
responsible to remove obsolete nodes from the graph.
Note that the BuildFileNode does not own source file nodes as these are created
and owned by DirectoryNodes during repo mirroring.

When buildfile X is modified yam detects this change and will set SourceFileNode
X and BuildFileNode X dirty. Next build these nodes will re-execute. When file X
has changed BuildFileNode X will re-process file X. This will update the set of
command and generated file nodes owned by BuildFileNode X.

When a new buildfile X is created in directory D yam detects a change in D and
will set DirectoryNode D dirty. At next build DirectoryNode D will be 
re-executed and will will pick-up X. The directory node creates a SourceFileNode
for X and a BuildFileNode on SourceFileNode X. The directory node owns the
new nodes and adds them to the graph.
After completion of the mirror update yam will execute all dirty nodes. These
include the new SourceFileNode X and BuildFileNode X.

When buildfile X is deleted from directory D yam detects both a change in 
buildfile X and in directory D. This causes SourceFileNode X, BuildFileNode X
and DirectoryNode D to be set dirty. Next build DirectoryNode D will re-execute
and notice that SourceFileNode X no longer exists. It will then request 
BuildFileNode X to remove all its command and generated file nodes from the
graph and will then remove SourceFileNode X and BuildFileNode X from the graph.


Note: the design in this document requires repos to be mirrored in the graph.
In design_getRidOfRepoMirroring.txt however it was decided to get rid of repo
mirroring as proposed in design_whenToAddSourceFileNodesToGraph.txt. The main
reason to get rid of mirroring was the long time it will take (in the first 
build) to hash all files in the repo. But as explained in 
design_getRidOfRepoMirroring.txt, it is no longer necessary to compute the file
hashes during mirroring. Instead hashing a file is only done when it is detected
as a dependency of a command. Hence only, relatively cheap, directory hashes need
to be computed during mirroring.
    
---Detailed description of 2-phase processing of buildfiles
Phase 1: 
    Foreach outdated buildfile node {
        Parse build file
        For each rule in build file {
            Find/create CommandNode
            For each rule output file {
                Find/create GeneratedFileNode
                Add to command output nodes
            }
    }

Phase 2:
     Foreach outdated buildfile node {
         Foreach command node C created from this build file {
              inputNodes = {}
              For each input file F of C {
                  generatedNode = findGeneratedFileNode(F)
                  if (generatedNode != null) {
                      inputNodes.add(generatedNode);
                  } else {
                      sourceNode = findSourceNode(F)
                      if (sourceNode == null) throw error;
                      inputNodes.add(sourceNode);
                  }
               }
               C.setInputs(inputNodes)
               C.script = rule.script
        }
    }

Note that this allows (non order-only) input generated files to be selected by
globs. For example:
: foreach *.c |> gcc -c %f -o %o |> outputDir\%B.o // compile all c-files 
: outputDir\*.o  |> gcc %f -o %o |> program // link the resulting object files
Note that evaluating this glob is O(N) where N is number of nodes in the DAG. 
N can be reduced by only applying the glob to generated files nodes that are in
scope, i.e. the nodes defined in this buildfile and its buildfile dependencies.

---Dynamic outputs
Some users of tup complain about having to declare all outputs of a rule.
E.g. tup cannot support a cmd script that unzips a zip file. In yam we consider
supporting this scenario, e.g. by : 
     |> unzip archive.zip outputdir |> outputdir\*
yam will detect the output files at command execution time and create for each
detected output file a GeneratedFileNode. Such dynamically detected outputs 
cannot be specified as rule inputs. It is possibly though to specify an 
order-only input glob. E.g. 
: |> unzip archive.zip outputdir & echo done > outputdir\done.txt |> outputdir\* outputdir\done.txt
: | outputdir\done.txt |> zip outputdir out.zip |> out.zip

or, using tup's group/bin feature:
: |> unzip archive.zip outputdir |> outputdir\* {unzip}
: | {unzip} |> zip outputdir out.zip |> out.zip