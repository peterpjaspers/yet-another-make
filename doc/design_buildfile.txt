---Build systems and their buildfiles
Build systems allow developers to define the command DAG in one or more buildfiles. 
Two types of buildfile syntaxes can be distinguished:
    - declarative Domain Specific Language (DSL)
      Examples: make's makefiles, tup's tupfile, mrmakes rules, tools and dep files.
    - imperative General Purpose Language (GPL)
      The buildsystem provides a library to facilitate command node creation.
      Examples: Bazel's Skylark, tup's Lua

---Yam buildfile
No consensus seems to exist on what approach is best nor on what GPL or DSL is best.
Yam therefore choses, at least for now, to support a hybrid approach inspired by 
tup's rule syntax and by tup's 'run script' feature. In this approach a yam 
buildfile is an executable program with a well-known name, e.g. buildfile.yam.
When executing a buildfile it outputs rules to stdout. Rule syntax is derived from
tup, see section Rule syntax.
Yam interprets the rule output to create command nodes in its DAG.
Note: buildfiles will typically be written in script languages like python
or ruby, e.g. buildfile_yam.py, buildfile_yam.rb. Such files must be passed
to their interpreter, e.g. python buildfile_yam.py. Yam must therefore be
told how to execute the buildfile. E.g. by config file like
    *.rb => ruby %f
    *.py => python %f

Yam makes no assumptions about the language used by the buildfile program.
This implies that yam does not provide a GPL support library to facilitate
generating rules. E.g. a function to generate a compile rule, a link rule, etc.
These functions simplify buildfiles to a series of calls to functions that output
the appropriate rules.

Note: Yam has/had the ambition to support a buildfile language that strictly
seperates rule definitions from dependency declarations. This is hard to
implement without a DSL. Yam drops this ambition, at least for now.

---Buildfile processing
Buidfile processing is the process of executing the buildfile, interpreting
the buildfile output rules and creating command nodes and generated file
nodes.

A file is represented in the graph by a FileNode instance.
A file is a source file or a generated file. It is not possible to distinguish
a source from a generated file by its name because yam does not enforce file 
naming conventions.

When interpreting the buildfile output for each rule one ore more (in case of
a foreach rule) CommandNodes will be constructed and added to the graph. When 
creating a CommandNode it must be passed FileNodes for its cmdInputs, 
order-only-inputs and outputs. Order-only-input and output nodes are FileNodes
for generated files, cmdInputs can be FileNodes for source and/or generated
files. The command node will ensure that the commands that generate the 
order-only-inputs and generated cmdInputs are executed before the command 
script is executed. This requires that:
    - The command node can distinguish a source from a generated input file.
    - It is possible to find the command node that produces the generated file.
    - The command node knows its generated input files before it is executed.
    
Note: file repositories are mirrored in the build graph.
When executing the very first build the mirrored directory tree will only
contain source file nodes. All these nodes can either be looked-up in the 
mirrored tree or directly (and faster) from the graph. After buildfile 
processing the graph, not the mirrored tree, will also contain generated
file nodes. 
When executing the next build the mirror will pickup the files generated by
the first build. The mirroring logic finds associated generated file nodes in 
the graph. So there is no need for the mirroring logic to be able to
distinguish source from generated files because generated file nodes are
created before the generate files are produced.
Exception: user deletes buildstate but not the generated files. In this
case the stale generated files are mirrored as source files. When creating
the generated file nodes yam will detect this conflict and prompt the
user to delete all stale generated files.

Design aspects:
    1) Class design
       a) FileNode has a reference to the CommandNode that produced it.
          If this reference is null than the FileNode is a source file.
          The producer field will be set once the rule is processed that
          defines the command that produces the generated file. 
       b) FileNode has subclasses SourceFileNode and GeneratedFileNode
          The latter has a reference to the CommandNode that produced it
          and that can only be set at construction time.
       c) FileNode has subclasses SourceFileNode and GeneratedFileNode
          The latter has a reference to the CommandNode that can be set
          at any time.
    2) Number of processing phases
       a) 1-phase (only in combination with 1a and 1c)
          The inputs of a command node are all FileNodes. Only after 
          processing of all buildfiles the commands are ready for execution
          because only then one can be sure that the producer fields of all
          generated file nodes are properly initialized. 
       b) 1.5-phase
          If a generated file GF is defined as the output of a rule in
          buildfile Y and GF is referenced as input of a rule in buildfile X
          then Y is processed before X. This ensures that the generated file
          node for GF exists when X is processed. After processing of X the
          commands produced by X are ready for execution.
          Buildfile X is said to depend on buildfile Y. Either the user 
          defines this dependency or yam is able to automatically derive the
          dependency by using naming conventions (as tup does).
       c) 2-phase
          First phase creates all command nodes and generated file nodes for 
          their output files.
          Second phase initializes the inputs of the command nodes created in
          first phase.
          Only after processing of the second phase are the commands produced
          in the first phase ready for execution.
       d) 1-phase with support for globs in generated files
          The assumption here is that a glob operate on a mirror directory tree
          that includes the generated file nodes. Note that the first mirror
          will not contains generated files because none of the commands that
          produce them has yet been executed. Therefore generated file nodes
          must be added to the mirror during buildfile compilation.

          Step 1: execute all build files and parse the produced rules
          Note: execution/parsing can be done in threadpool.
          outputMap = {}

          Step 2: expand input and output specs to path lists.
          for each rule {
              expand input spec:
                   path/glob on source files will produce final result, 
                   path/glob on generated files will produce a possibly 
                   incomplete result because the directories may not yet 
                   contain all generated file nodes.
                   An input sourcefile/glob will find SourceFileNodes, an
                   input generatedfile/glob will only find already compiled
                   GeneratedFileNodes.
               expand output spec:
                   Resolve %-flags in output spec
                   Add outputs as GeneratedFileNodes to directories
                   Note: the list of output nodes is incomplete in case of 
                   incomplete result in input generatedfile glob AND output spec
                   refers to inputs (%-flags).
               Add output nodes outputMap
                   var expandedRule = {inputs, outputs, rule}
                   foreach output: 
                       expandedRules = outputMap[output]
                       expandedRules+= expandedRule
                       if (!output.isGroup && expandedRules.size > 1: throw error
                       outputMap[output] = expandedRules
                   Node: expandedRule is like a possibly incomplete CommandNode
          
          Step 3: Re-evaluate input globs on generated files
              do {
                  newOutputs = do step 2
              while (!newOutputs.empty);
          Note: newOutputs can only be found when input specs are globs on
          generated files that were not yet defined during previous step-2
          execution. 
          Note: when generated inputs are not referenced by output specs then 2
          step-2 executions will result in complete lists of input paths. 
          Note: it is not common use-case to reference generated inputs in
          output spec (e.g. a link rule will not do such thing).
 
          Step-4: Construct the expanded rule dependency graph:          
          Merge the per-buildfile output maps into a global output map.
          Duplicate outputfiles => error
          For each rule {
              inputDependencies = {}
              for each input {
                  if sourcefile: continue
                  expandedRules = globalOutputMap[input]
                  if expandedRules.empty: error (input references non-existing
                      generatedfile)
                  inputDependencies += expandedRules 
              }
          }
          Detect cycles in rule graph. Cycles => error
          Note: recover from error by removing the newly created generatednodes
          from directories.
          
          Step 5: Commit: compile expandedRules into CommandNodes and GeneratedFileNodes
          and add them to the context. 
          Alternative: implement expandedRule as  CommandNode. Commit finds whether
          node already exists in context. If so: update it, else create new one.
          Idem for GeneratedFileNode.

          Pros:
              - rule order in buildfiles does not matter
              - relieves user of specifying buildfile dependencies
              - cyclic buildfile dependencies are no problem as long as
                the expanded rules dependencies are not cyclic.
                (although a warning is probably in-place).
          Cons:
              - O(N), N being number of output files+groups
                Or can algo be incremental, N being number of modified buildfiles?
                I don't think so.
              - outputMap must be stored in buildstate or reconstructed during
                first build after startup
          Attention: group content order is not deterministic
          

2a and 2c (1-phase and 2-phase) require all buildfiles to be processed before
command execution can begin. This limits scalability.

2b (1.1-phase) only requires a subset of all buildfiles to be processed before 
the commands defined in a buildfile can be executed. This enables parallel 
processing of buildfiles and execution of command nodes. The amount of parallel
processing depends on the buildfile dependency graph. E.g. if 1 buildfile
depends on all the others then there will be no parallel execution.

Given these design aspects there are 5 possible design scenarios:

1a+2* (FileNode with optional producer, any nr of processing phases)
Assume the user mis-spelled the name of a generated input file. The buildstate
will not contain this name because no source file of that name exist. 
Hence a FileNode is created (with its producer being null) under the assumption
that it is a generated file and that the node's producer will be initialized 
once the build file is processed that defines the rule that produces that 
generated file. But this will not happen because of the mis-spelled name. As a
consequence the command script will fail because it references a non-existing 
input file. This violates the fail-early principle.

1b+2a (SourceFileNode/GeneratedFileNode mandatory producer, 1-phase)
This combination is not possible because a rule with a generated input file
for which no GeneratedFileNode can be found can not construct the 
GeneratedFileNode itself because it does not know its producer.

1b+2b (SourceFileNode/GeneratedFileNode mandatory producer,  1.5-phase)
When the proper buildfile dependencies of buildfile X have been processed then
during processing of X the graph will contain all generated input nodes
referenced by X.
In case of missing buildfile dependencies or mis-spelling of a source or
generated input file the graph will not contain a matching SourceFileNode/
/GeneratedFileNode. In this case buildfile processing fails and the user must
correct his error (i.e. fix buildfile dependencies declaration or fix spelling
of input file name).

1b+2c (SourceFileNode/GeneratedFileNode mandatory producer, 2-phase)
When in second phase no matching input node is found due to mis-spelled name
then buildfile processing fails. It is clear that the mis-spelled name is 
refering to a generated file

1c+2a (SourceFileNode/GeneratedFileNode optional producer, 1-phase)
Similar to 1a+2a. Error can be detected at start of executing a command that 
has a GeneratedFileNode with null producer. So detection is earlier than in
1a+2* scenarios, but still not optimal.

1c+2b (SourceFileNode/GeneratedFileNode optional producer, 1.5-phase)
Same as to 1b+2b.

1c+2c (SourceFileNode/GeneratedFileNode optional producer, 2-phase)
Similar to 1a+2a. Error can be detected during phase 2, so before command
execution can start.

The design 1b+2b (SourceFileNode/GeneratedFileNode and 1.5-phase) is
attractive because:
    - it enables parallel processing of buildfiles and commands
    - it fails early and is able to produce an error message that explains the 
      two possible causes of the error (incomplete buildfile dependencies or
      mis-spelled input file.)
      
Disadvantages of design 1b+2b:
    - user must define buildfile dependencies
    - buildfiles cannot be cyclic dependent

Robustness of 1b+2b for other user errors:
-- Removing a rule while not removing references to the its output files.
   Assume buildfiles X and Y. A rule in X uses input file F that is generated 
   by a rule in Y. So X depends on Y. The user now removes that rule from Y but
   forgets to remove the reference to F from buildfile X.
   Yam handles this as follows:
       - X depends on Y. When Y changes than both Y and X, in that order, will
         be reprocessed.
       - Processing of X detects that F does not exist (no source file F exists
         nor generated file F exists). Yam raises an error, the build fails.
   Note: in the 1- and 2-phase scenarios stale references can only be detected
   after all buildfiles have been processed. 
-- Cycles between build files.
   Buildfile X refs output file F defined in Y, Y refs outputfile G defined in
   X. Yam cannot handle this because X and Y are represented as nodes. Y is 
   requisite of X, X is requisite of Y. This will cause a deadlock. Yam must 
   detect this cycle and fail the build. 
   Note: the 1-phase and 2-phase processing options can handle this situation.
-- Cycles between rules.
   If the cycling rules are defined in two buildfiles then see above.
   Cycles between rules in one buildfile: assume rule A produces F, rule B
   produces G. A has input G, B has input F. A is defined before B. When
   interpreting rule A yam cannot find the filenode for G. Yam raises an error, 
   the build fails.
   Note: the 1-phase and 2-phase processing options can only detect this 
   once all buildfiles have been processed.


---Buildfile dependencies (in 1b+2b)

A buildfile is an executable program that outputs rules that are interpreted by
yam to produce a set of command and generated file nodes. The process of 
executing the buildfile and subsequent interpretation is called buildfile 
processing.

Yam will re-process the buildfile when the buildfile program text and/or one or
more of the buildfile's input dependencies change. Yam supports three types of 
buildfile input dependencies:
    - buildfile
      Buildfile X depends on buildfile Y when X uses definitions made in Y.
      For now only generated files defined by Y. Later perhaps also variables.
      Yam will process Y before X.
      Given design choice 1b+2b it is up to the user to declare the buildfile
      dependencies. Options:
          - declare the buildfile dependency graph in a special file
          - each buildfile outputs the names of it buildfile dependencies
      Decision: each buildfile outputs its buildfile dependencies
    - source file
      Buildfile X depends on src file F when F is read during execution of X.
      Yam will detect such dependencies by monitoring file access of X.
    - directory
      Buildfile X depends on directory D when the set of command nodes defined
      by X depends on the content of D or when a directory is specified as
      rule input. E.g. a buildfile that produces a rule that has an input glob
      on directory D depends on D. E.g. a buildfile that outputs a rule for 
      each .cpp file in directory D depends on D.
      Note: in the first example the yam interpreter evaluates the glob on D 
      and yam will add D to the input dependencies of X. In the second example 
      the buildfile program evaluates the glob on D. Yam however cannot detect 
      directory iteration. The buildfile must therefore output its directory
      dependencies. This is error-prone. In case of mistakes the user will
      quickly notice this (e.g. a new source file will not be compiled).


Perhaps yam could detect directory dependencies like it does detect file 
dependencies. In mrmake directory dependencies and dependencies on non-existing
files were ignored because they often cause unnecessary re-execution. E.g.
a compilation command node searches an include file F by iterating directories
P, Q and R respectively. Assume F is found in R. Now all changes in P, Q and R
cause re-execution of the buildfile/command while only modifying F or moving F
to P or Q or adding a P\F or Q\F justifies such re-executions.
On the other hand: if such a change takes place then the compilation must be
re-executed. How to solve this? 
An easier case is when F is searched by using file_exists calls for P\F, Q\F 
and R\F (assuming file_exists calls can be monitored). In this case one would
register input file dependencies on P\F, Q\F and R\F. Moving F or adding P\F 
or Q\F then correctly results in re-executing the compilation command.

---Rule syntax
Yam rule syntax is simplified tup rule syntax. See file rule_syntax.txt.
Simplifications: no variables, subset of flags. 
Things could be be further simplified by removing foreach support. The foreach is
then implemented in the GPL in the buildfile program. This eliminates substitution 
of %f and other flags. The cmd script can be passed literally to a shell or directly
to the OS. Without foreach a rule defines one command.
For the time being yam will support foreach rules. Rationale: Yam caches directories
and glob results. Such caches cannot be implemented in the buildfile logic. Hence
yam foreach support will result in faster processing of buildfiles.

---BuildFileProcessingNode
Processing of a buildfile is performed by a BuildFileProcessingNode.
BuildFileProcessingNodes are stored in the graph. BuildFileProcessingNode keeps
track of the command and generated file nodes that it created from the rules.
It is responsible to add these nodes to the graph and to remove them from the 
when the rules from which they were created are deleted/changed.

For each directory there is 0 or 1 BuildFileProcessingNode.
When a buildfile X is created in directory D yam detects a change in D and
will set DirectoryNode D dirty. At next build DirectoryNode D will be 
re-executed and will will pick-up X. The directory node creates a SourceFileNode
for X and a BuildFileProcessingNode D for SourceFileNode X. The directory node 
owns the new nodes and adds them to the graph.
After completion of the mirror update yam will execute all dirty nodes. These
include the new SourceFileNode X and BuildFileProcessingNode D.

When buildfile X is modified yam detects this change and will set SourceFileNode
X dirty, which propagates to BuildFileProcessingNode D. Next build these nodes
will re-execute. When file X has changed BuildFileProcessingNode D will 
re-process file X. This will update the set of command and generated file nodes 
owned by BuildFileProcessingNode X.

When buildfile X is deleted from directory D yam detects both a change in 
buildfile X and in directory D. This causes SourceFileNode X, 
BuildFileProcessingNode D and DirectoryNode D to be set dirty. Next build
DirectoryNode D will re-execute and notice that SourceFileNode X no longer
exists. After completion of the mirror update BuildFileProcessingNode D will
re-execute, detect that X has been deleted and remove all its command and 
generated file nodes from the graph.
When buildfile X is deleted then DirectoryNode D will remove processing node D.
When buildfile X is replaced by Y (e.g. buildfile_yam.rb replaced by 
buildfile_yam.py) DirectoryNode D will associate processing node D with Y.
Note: BuildFileProcessingNode D1 may depend on BuildFileProcessingNode D2.
When the buildfile in D2 is deleted processing node D2 will be removed from
the graph. D1 however still references D2. D1 will re-execute discover that
D2 is deleted. If D1 still depends on D2 (because user forgot to remove
the dependency of D1 on D2) then it fails.

When yam buildfile X is changed/deleted it sets X dirty which propagates
to BuildFileProcessingNode X which propagates to any BuildFileProcessingNode Y
that depends on BuildFileProcessingNode X (because X creates GeneratedFileNodes
referenced by Y). After X completes, Y will re-process and discover that 
it references GeneratedFileNodes that no longer exist in the graph.
Build fails, user is prompted to remove the dangling reference from Y.

Note: the design in this document requires repos to be mirrored in the graph.
In design_getRidOfRepoMirroring.txt however it was decided to get rid of repo
mirroring as proposed in design_whenToAddSourceFileNodesToGraph.txt. The main
reason to get rid of mirroring was the long time it will take (in the first 
build) to hash all files in the repo. But as explained in 
design_getRidOfRepoMirroring.txt, it is no longer necessary to compute the file
hashes during mirroring. Instead hashing a file is only done when it is detected
as a dependency of a command. Hence only, relatively cheap, directory hashes need
to be computed during mirroring.
    
---Detailed description of 2-phase processing of buildfiles
Phase 1: 
    Foreach outdated buildfile node {
        Parse build file
        For each rule in build file {
            Find/create CommandNode
            For each rule output file {
                Find/create GeneratedFileNode
                Add to command output nodes
            }
    }

Phase 2:
     Foreach outdated buildfile node {
         Foreach command node C created from this build file {
              inputNodes = {}
              For each input file F of C {
                  generatedNode = findGeneratedFileNode(F)
                  if (generatedNode != null) {
                      inputNodes.add(generatedNode);
                  } else {
                      sourceNode = findSourceNode(F)
                      if (sourceNode == null) throw error;
                      inputNodes.add(sourceNode);
                  }
               }
               C.setInputs(inputNodes)
               C.script = rule.script
        }
    }

Note that this allows (non order-only) input generated files to be selected by
globs. For example:
: foreach *.c |> gcc -c %f -o %o |> outputDir\%B.o // compile all c-files 
: outputDir\*.o  |> gcc %f -o %o |> program // link the resulting object files
Note that evaluating this glob is O(N) where N is number of nodes in the DAG. 
N can be reduced by only applying the glob to generated files nodes that are in
scope, i.e. the nodes defined in this buildfile and its buildfile dependencies.
Also see section ---Input globs on generated files

---Dynamic outputs
Some users of tup complain about having to declare all outputs of a rule.
E.g. tup cannot support a cmd script that unzips a zip file. In yam we consider
supporting this scenario, e.g. by : 
     |> unzip archive.zip outputdir |> outputdir\*
yam will detect the output files at command execution time and create for each
detected output file a GeneratedFileNode. Such dynamically detected outputs 
cannot be specified as rule inputs. It is possibly though to specify an 
order-only input glob. E.g. 
: |> unzip archive.zip outputdir & echo done > outputdir\done.txt |> outputdir\* outputdir\done.txt
: | outputdir\done.txt |> zip outputdir out.zip |> out.zip

or, using tup's group/bin feature:
: |> unzip archive.zip outputdir |> outputdir\* {unzip}
: | {unzip} |> zip outputdir out.zip |> out.zip

---Garbage collection
How to deal with storing references to command and generated file nodes that
are removed from context->nodes()? Given PersistentBuildState implementation 
these cannot be stored.

--Solution 1: nodes must be kept in context->nodes() in state Deleted. 
In context->computeStorageNeeded:
  foreach node in Deleted state:
     if useCount==1: remove from nodes(), add to toRemove
     else if modified: add to toReplace
     else: do nothing

--Solution2: nodes set to state Deleted and removed from nodes().
In context->computeStorageNeeded: no changes needed
In PersistentBuildState: TBD

--Solution3: force nodes that refer to Deleted nodes to remove their reference.
Assume CommandNode A in buildfile BFA references commandNode B because A depends
on file G that is generated by B in buildfile BFB. BuildFile BFA depends on BFB. 
So when BFB is modified Yam sets BFB Dirty and propagates Dirty to BFA. BFA is
processed after completion of BFB and detects Deleted G and fails the build. 
Hence there can be no references to deleted command/generated nodes.
What if a command node references a deleted file node? Then the commandnode is
also set Dirty and executes. It either succeeds because it no longer depends on
the deleted source file or it fails. In first case ref to deleted source file 
is removed and use-count drops to 0. In second case user must update script to 
no longer ref deleted source file and restart build. In the end no references
to the deleted source file will exist and use-count drops to 0.
Conclusion: this design ensures proper garbage collection ONCE all dirty
BFPNs have completed execution. 
What happens when a store operation is done while e.g. BFB has completed (i.e.
B and G are removed from context) and BFA is still in progress (and still 
referencing G)?
B and G are no longer on context and will be removed from storage. BFA has not
yet completed execution and hence has not yet updated A. Hence A is still
!modified will not be replaced in storage. Note that updating the commands
generated from a buildfile is an atomic operation wrt storage because both
operations are executed in mainthread.

Storage to persistent buildstate however can
happen at any time. E.g. after BFB has completed and removed B and G then BFA
still references Deleted G which is no longer in context.nodes(). This will 
causeG to be removed from persistent storage. When streaming A an error occurs
when A attempts to stream G: object not registered for storage.
But...A will not be streamed because it still is !modified. 
Conclusion: hard to analyze correctness of this solution.


---Parallelizing repo mirroring and buildfile processing
Now: first mirror repos, then execute dirty BuildFileProcessingNodes (BFPN).
What if both are done in parallel?

Now: BFPN looks-up directory node in context->nodes(). When such a lookup fails 
then buildfile references a non-existing directory and build fails.
When lookup to filenode fails then buildfile is either referincing a
non-existing source file or a non-existing generated file and build fails.

Then: baseDir node exists because else BFPN would not exist. baseDir is
mirrored. So failing lookups inside baseDir must fail the build.
There can however also be lookups outside baseDir by inputs like ..\src\*.cpp
or <anotherRepo>\src\*.cpp. Such lookups will fail in DirectoryNode::findChild
call made by Globber. It is not straightforward to handle this: missing dirs
must be communicated back to BFPN which must create these nodes, execute them
and then retry Globber.
When file lookup fails: create source file node and execute it. Remove it when
file does not exists and fail the build. Else continue.

---Input globs on generated files.
At time of writing input globs are executed on mirrored directory nodes by
Globber. Dir nodes should only contain source dirs/files. So globs on generated
files like *.obj will not work

Besides that, the search domain of an input gen file glob in rule R in buildfile
BF A must be restricted to the output files defined in the buildfiles on which
BF A depends. E.g. an input glob **\*.obj in a rule in BF A would match all
object files defined by all buildfiles in the current dir tree, even while A 
only depends on 1 other buildfile.
Conclusion:
    - it makes no sense to include gen file nodes in the directory tree
    - the search domain of genfile glob must be restriced to the output files
      defined in the buildfile on which it declared itself dependent.
The above holdes for the 1.5-phase processing model, not for the multi-phase
model.

Problem: unless buildfile syntax differentiates between source and generated
file globs one cannot tell whether a glob will match source files or generated
files or both. This implies that a glob cannot be executed as prerequisite of
the buildfile (as is currently the case). Its execution must be postponed
to the compilation of the rule that uses it.

Simplification (a la tup): globs do not match directories. E.g. src*/*.cpp and
**/*.cpp do make sense which src/*.cpp, ../src/*.cpp and mod1/src/*.cpp do.
Or extend syntax to differentiate between globs that will only match source
files and globs that will only match generated files.
Source file globs are re-usable, gen file globs are not because their matches
depend only on the outputs of rules preceding the glob.


Possible solutions:

1. Add generated file nodes to directory. Directory  keeps track of generated
file nodes seperate from source file nodes. Directory does not own these nodes.
Add/remove is responsibility of BuidFileProcessingNode. NB: directory must exist,
else error.
2. Variables with substibution. E.g.
       SRCS=*.cpp
       OBJS=$(SRCS, output\%B.obj)
       : foreach $(SRCS) |> cc -%f -o %O |> output\%B.obj
       : $(OBJS) |> link %d -o %O |> program.exe
   Redundant: output\%B.obj appears twice
   Also this is not globbing.
   
3. BFPN collects all outputs in an anonymous GroupNode. This group is passed to
Globber. Globber now searches in directories and in groups. This can be expanded
to explicity named groups.
  %g<groupPath> matches all nodes in specified group.
  %g<groupPath>/*.obj matches all obj nodes in specified group.
Note: the input groups must be passed to CommandNode as part of cmdInputs.
Note: When a groupPath occurs in buildfile A and B the BFPN_A and BFPN_B both
add generated file nodes to this group. Assume buildfile B uses the group
as input. Then B must depend on A in order for the group content to be complete.
If not then the command that uses the group must delay execution until all
buildfiles have been processed. Detecting missing, dependency declarations
is not possible during buildfile processing. The problem can be avoided by,
unlike tup, making groups global for read-access but local for write-access.
I.e. only one buildfile can add to a group. In that sense the BFPN produces
the group. The group name declard in producer is a string, not a path. The
group node name is a path: <sym path of dir of buildfile>\<group name>
Readers of the group refer to the group by the (symbolic) group node path.

Note: tup automically finds buildfile dependencies: it first parses buildfiles
in directories referenced in input paths/globs. This is simplified by the fact
that tup does not support ** globs. It then parses the buildfile itself.

--Output groups
A rule in BFI that has uses an output group G as input must have deterministic content
of G. BF1 must therefore specify as dependencies all buildfiles that output to G.
In the tup example
    #./submodules/sm1/Tupfile
    : foo.c |> gcc -c %f -o %o |> %B.o ../<submodgroup>

    #./submodules/sm2/Tupfile
    : bar.c |> gcc -c %f -o %o |> %B.o ../<submodgroup>

    #./project/Tupfile
    : baz.c | ../submodules/<submodgroup> |> gcc -c %f -o %o |> %B.o

tup will determine the buildfile deps of ./project/Tupfile by finding all buildfiles
in the ../submodules directory tree.
This implies that the buildfile dependencies are defined by glob ../**/buildfile_yam*
Yam can adopt the same convention and add such deps automatically or the user 
must be able to specify buildfile deps like: buildfile ../**/buildfile_yam*.
The latter is error-prone. An incomplete spec will cause non-deterministic group
content and may cause parse/compile errors when the group contains outputs from
non-declared buildfiles.
Decision: 
    - group dependencies are solved by yam.
    - yam supports both bins and groups.
    - yam adds output (generated files) to respective directories
      Thus enabling globs on generated files.

--Recover from parse/compile errors.
Current implementation modifies existing commands. These modifications are not
rolledback when a later error occurs in the processing of that buildfile/rule.
E.g. in a foreach rule some of the generated inputs do not exist. Some commands
are updated, others not. 
Commands and GeneratedFileNodes must only be added/modified when all are ok.
Possible implementations:
    - rollback from PersistentBuildState
    - store info in tmp objects until all processing is done. Then commit to 
      existing objects, store new objects in buildstate, remove obsolete objects
      from buildstate.
    - backup existing objects before modifying them. On error: rollback from
      existing objects.
