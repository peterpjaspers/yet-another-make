Todo
-ExecutionContext
  To avoid singletons a context object is passed to Node constructor.
  Add access to:
	- command line options
	- logBook
	- abort build token
- Command node:
    - file dependency detection
        - define dependency detection interface, e.g. dependencies = track(program)
        - pluggable dependency detection implementation
        - script communicates file dependencies via stdout to YAM or 
          via files (as Microsoft's filetracker and tup's dllinject)
        - YAM provides file dependency detection support a la MS filetracker
          Consider reuse of tup dependency detector
    - integrate file dependency detectionIn CommandNode
    - handle the race-conditions described in the last 2 notes in the description of
      FileNode.h
    - distinguish between modifications caused by user editing source files and tampering
      (e.g. deleting) with generated files.
      Note: not doing 
- build state storage
    - implement streaming btree (provides streaming of value types into btree via ValueStreamer i/f)
    - implement ObjectStreamer (streams C++ objects to/from ValueStreamer)
    - implement BuildStateStreamer (streams YAM buildstate)
- winkin (build cache)

- build file format (follow tup, follow mrmake, something completely different?)
    - decide
    - implement parsers and DAG updater

Done
- ExecutionContext
  To avoid singletons a context object is passed to Node constructor.
  It provides access to:
	- node repository (renamed from Graph)
	- main thread and thread pool and their dispatchers
	- file aspect hasher configuration
- filenode, sourcefile, generatedfile (output file of command node)
- Process class => boost process
- file aspect hashes
    - FileNode::_hashes (std::map<aspectName => XXH64_hash_t)
      _hashes is populated when node is created and updated when context.filehashers changes
      and file name matches one of filehashes patterns.
      Note: it is more attractive to only add aspects to filenode that are actually used.
      With this approach it may happen that hashes are computed that are never used.
      Unfortunately this is not possible because it cannot be known in advance which commands
      will use a file as input.
    - CommandNode::_inputAspects (std::vector<{fileNamePattern, aspectName}>)


  In our latest discussion we stated that all inputs and outputs must be modeled as nodes.
  This would allow us to compute executionHash in Node class (instead of making it a
  sub-class responsibility).
  
  Analysis:
  In its simplest form command node class needs a member field: string _script;
  Command node executionHash = hash(hash(_script), hash(input files), hash(output files))

  Modeling the script as a node (holding the script string) incurs overhead: 
	- memory: for each command node also a script node
	- threadpool: script node execution will hash the script text in thread pool.
          Hashing the script text is very fast. The overhead of posting this operation
          is probably larger than the hashing itself.
  
  To avoid this overhead I propose the following implementation:

  Node class has (a.o.) the following member functions:
      protected:
          XXH64_hash_t computeExecutionHashExt(std::initializer_list<XXH64_hash_t> otherHashes) const;
      public:
          virtual XXH64_hash_t computeExecutionHash() const { return computeExecutionHash({});}

  Pseudo-code of computeExecutionHash(otherHashes): { return hash(output node hashes, input node hashes, otherHashes)); }

  Command node class has member field: string _script
  Command node overrides computeExecutionHash: return computeExecutionHash(hash(_script));
  Note: there are 2 situations in which CommandNode::computeExecutionHash is called:
	- during self-execution of the command node, in thread pool, immediately after completion of
          command script. The hash is stored in Node::_executionHash
        - after completion of command prerequisites execution to figure out whether command self-execution
          is pending: pending =  _executionHash != computeExecutionHash()

  File node overrides computeExecutionHash(): return hashFileContent(_name);
  Because computeExecutionHash() is potentially expensive it is intended to be called only 
  during self-execution of the file node.
  In that case it obviously makes no sense to implement file node pending as: pending = _executionHash != computeExecutionHash()
  Instead the implementation is: pending = _state == State::Dirty
  A file node must be set dirty at start of alpha-build and, during beta-build, when the file is write-accessed.

  See https://miro.com/app/board/uXjVO-7wAmU=/ 
  In this board a build file node generates all command nodes, including the command scripts.
  The build file may reference files (e.g. a file that contains a version nr) and globs (e.g. 
  to create a compile command for each cpp file found in the src directory).
  The execution hash of a build file node the becomes:
	executionHash = hash(hash(input build files), hash(other input files), hash(input globs))
  Note: the output command nodes are not part of this hash because there is no way
  that the user can tamper with this output.
  Note: files and globs are nodes.

- What node info can be updated in threadpool context and what not?
  E.g. at first glance updating Node::_executionHash, FileNode::_lastWriteTime in ThreadPool seems harm-less
  Why? Because no other threads rely on this data while the node execution is in progress.
  E.g. detecting a input include file during C++ compilation requires creation of a FileNode and
  computation of the include file hash(es). The hashing must be done in threadpool. Adding the new node
  to Graph however must either be done in graph critical section or in main thread context.
  Changing Node::State is another example that must either be done in critical section or main thread.
  Why? Because node's that execute their prerequisites inspect Node::State to figure out which prerequisites
  need to be started.
  
